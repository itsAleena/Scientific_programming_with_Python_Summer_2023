{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0eb8165c-e07e-453d-b0f4-416ec73102c8",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-515e01b25bda86a9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Exercises and Homework for week 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a8175c-254d-4672-a528-198e33c71bc8",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-14ca577e70096fbf",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## physics725: Scientific Programming with Python (SS 2023)\n",
    "\n",
    "Oliver Cordes & Thomas Erben\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4dde1f5-e71a-4eb0-a8f7-962af1d24d5b",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-58e8949e2e41603c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Homework is due on **Thursday, 18/05/2023, 11:55pm**\n",
    "\n",
    " * You only learn a programming language by actively praticing and using it! We therefore **strongly** advise you to work on the homework problems.\n",
    " * Please discuss the problems with your student peers and with your tutor.\n",
    " * Your code(s) need(s) to be well and appropriately commented!\n",
    " * Submit this notebook and, if necessary, additional files in a `tar`-archive with name `Homework_5_group_XX.tgz` (replace `XX` with your group number) to your tutor.\n",
    "\n",
    "**Topics of this exercise:**\n",
    " * Working with multidimensional `numpy`-arrays \n",
    " * Basic plots with matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc594b8-94c9-4e26-8e9e-b6230dcd8d41",
   "metadata": {},
   "source": [
    "**Your group number here please:**  Group XX"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d75441-56db-4575-84de-204e0c2406e2",
   "metadata": {},
   "source": [
    "## 1. Lecture Review (0 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc8e483c-51ee-47a4-b68f-36bea2d40b0b",
   "metadata": {},
   "source": [
    "If you did the lecture review questions [05_Review_questions.ipynb](05_Review_questions.ipynb) (strongly recommended!): \n",
    "Please discuss with your tutor and your group any issues/problems you had with them.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d210c6b5-49be-4001-9630-212739e4eba3",
   "metadata": {},
   "source": [
    "## 2. Random Walk (15 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ada5f1a-8766-43cd-a112-1eff13f14120",
   "metadata": {},
   "source": [
    "We consider the one dimensional random walk. Starting from $x=0$ we walk in each time step a random step to the left or to the right with equal propability. We would like to estimate the quantities $\\langle d(t)\\rangle$ and $\\langle d(t)^2\\rangle$, where $d(t)$ is the distance from the origin at time $t$ after $N$ steps. With a simulation, we want to confirm known results from statistical mechanics:\n",
    "\n",
    "$$\n",
    "\\langle d(t)\\rangle = 0\n",
    "$$\n",
    "and\n",
    "$$\n",
    "\\langle d(t)^2\\rangle = N\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e10bfe2-88f6-4e27-be79-a93d9d2fded4",
   "metadata": {},
   "source": [
    "<img src=\"figs/random_walk.png\" style=\"width: 300px;\" style=\"height: 200px;\">  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "473f5b8d-691a-4fae-bf1b-fd78d0d4b81a",
   "metadata": {},
   "source": [
    "**Task:**\n",
    "\n",
    "Obtain the desired quantities by simulating 1000 walkers and 200 time steps.\n",
    "\n",
    "**Hints:**\n",
    " * create a two-dimensional array with the walking stories of each worker in one direction and time in the other (see left side of the following figure)\n",
    " * the function `np.random.randint` allows you directly to create a 2D-array of random numbers)\n",
    " * use the created array to obtain another array containing $d(t)$ for each walker ($d(t)$ is just the cumulated sum of the individual steps; see right side of the following figure) (see `np.cumsum`)\n",
    " * obtain $\\langle d(t)\\rangle$ and $\\langle d(t)^2\\rangle$ and plot the quantities (applicate `np.mean` function along the stories-axis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a566cd-b69e-428d-bccc-6bb304c7dce7",
   "metadata": {},
   "source": [
    "<img src=\"figs/random_walk_schema.png\" style=\"width: 600px;\" style=\"height: 300px;\">  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ca5159-d8e8-46dd-8d9a-641f2cf5eb57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here please"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8171b135-35bb-4ed3-9b51-404ceaf6f806",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8a2408-ea8d-4e8a-a0a7-e1245dd78041",
   "metadata": {},
   "source": [
    "## 3. Weather temperature prediction (15 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "317a6ceb-c07e-4c40-a1ca-1b462edf05a4",
   "metadata": {},
   "source": [
    "Despite of modern techniques in creating weather models to get a almost real prediction of a temperature, you can also think of a simple data mining approach. For many of the regions on earth we have weather stations which feed their data into a global database. These data can be fetched and analyzed. For the temperature prediction we simply have look inside the data to see if we can find a similar temperture trend, so if we can find the same temperature development, we can use the next temperature in the archive as a temperature prediction for the recent temperature. If you find may similar events in the database you can analyse these events. Creating a mean value for all these temperature is in quite naive but gives at least a good starting point for further analysis.\n",
    "\n",
    "However, this is a simple approach, which neglects all know effects on the temperature development, land scapes, air pressure, clouds, winds, solar power etc. \n",
    "\n",
    "I think this is a funny task and one can check how good is this prediction in comparison to the modern models. At least it will take less cpu ressources ;-)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1234e1d8-ffa1-4b50-9edd-40ba6854257c",
   "metadata": {},
   "source": [
    "### Weather data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a9b394-6873-4456-82de-a200792af113",
   "metadata": {},
   "source": [
    "In the internet there is a package called `meteostat` (see https://dev.meteostat.net/python/) which offers you an access to global weather statistic data. If you know the weather station id, you can access different weather data time series. We focus on the hourly data from the weather station `Bonn-Roleber`. At the moment data can be downloaded from January 1st 2016 until now directly. These are the provided data:\n",
    "\n",
    "```\n",
    "                     temp  dwpt  rhum  prcp  snow   wdir  wspd  wpgt    pres   \n",
    "time                                                                           \n",
    "2016-01-01 00:00:00   4.7   2.1  83.0   0.0   NaN  180.0   9.7   NaN  1024.8  \\\n",
    "2016-01-01 01:00:00   4.3   2.0  85.0   0.0   NaN  200.0  13.3   NaN  1024.9   \n",
    "2016-01-01 02:00:00   4.7   2.1  83.0   0.0   NaN  190.0  11.5   NaN  1025.2   \n",
    "2016-01-01 03:00:00   4.6   2.3  85.0   0.0   NaN  190.0  11.9   NaN  1025.4   \n",
    "2016-01-01 04:00:00   5.0   2.9  86.0   0.0   NaN  200.0  17.6   NaN  1025.1   \n",
    "...                   ...   ...   ...   ...   ...    ...   ...   ...     ...   \n",
    "2023-05-04 06:00:00   9.4   4.6  72.0   0.0   NaN  105.0   9.3  16.7  1021.9   \n",
    "2023-05-04 07:00:00  11.5   5.1  65.0   0.0   NaN  110.0  11.1  18.5  1021.6   \n",
    "2023-05-04 08:00:00  13.9   5.8  58.0   0.0   NaN  117.0  13.0  22.2  1021.1   \n",
    "2023-05-04 09:00:00  15.9   6.1  52.0   0.0   NaN  123.0  14.8  25.9  1020.5   \n",
    "2023-05-04 10:00:00  18.0   5.9  45.0   0.0   NaN  127.0  16.7  27.8  1019.9   \n",
    "```\n",
    "\n",
    "For this task only the first column `temp` is interesting for as as well as the index `time`. The following code part, downloads the necessary data and can be used directly in your solution. Have a look at the code, so you can apply the solution to other quantities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "cc9c1024-d2e1-4f87-81f4-7e8951d82be2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from meteostat import Hourly\n",
    "\n",
    "\n",
    "# Set time period, only from 2016 until 2023 is supported\n",
    "start = datetime(2016, 1, 1)\n",
    "end = datetime.now()\n",
    "\n",
    "# Get hourly data\n",
    "# id: 10519 = Bonn-Roleber\n",
    "\n",
    "data = Hourly('10519', start, end)\n",
    "data = data.normalize()    # be sure that all data is available, \n",
    "                           # gaps are filled\n",
    "data = data.fetch()  \n",
    "\n",
    "\n",
    "# extract the times and the temperature data\n",
    "# and convert these to numpy arrays\n",
    "# the data is stored in pandas data frames, \n",
    "# which we not have in class so far!\n",
    "times = data.index.to_numpy()\n",
    "temps = data['temp'].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d98d33-ad1b-49fb-8d47-853fe1edfc50",
   "metadata": {},
   "source": [
    "The arrays `times` and `temps` are now have necessary data stored in 1d-`numpy`-arrays."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6b2fb8-aede-4a31-87fe-655377219266",
   "metadata": {},
   "source": [
    "The idea of a temperature prediction is to have a look in the data set if we can find $N$ consecutive values similar to the $N$ last recent values at a point $M$ insisde the archive data. The value $M+1$ follows the same $N$ values and is the *prediction* for the recent value. If more than one $M$ points are found, one can calculate the mean value for the prediction. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b23f14-9aa7-4421-ad91-b80b671dbab8",
   "metadata": {},
   "source": [
    "**Task:**\n",
    "\n",
    "The task is to check the archive data for the occurrence of $N$ consecutive values. Evaluate the points $M$ in the archive data and calculate a predicted value for the temperature from the mean values. A direct search may be without any results, so perform all tests with an inaccuracy of `0.1` degrees. $N=3$ should work. If you have still no results, vary the accuracy and number of data points!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0e9480-1f7e-4ac0-91ff-750a7d84c0e5",
   "metadata": {},
   "source": [
    "**Hints:**\n",
    " * use the *rolling window* technique to split the temperature data array (see *Review questions*)\n",
    " * use `np.isclose` and `np.all` to check for the occurences of the test data and collapse the results to a linear array (see *Review questions*)\n",
    " * `np.nonzero(...)[0]` gives you an index array for the found data positions; you need to adjust the positions for the predicted values, how?\n",
    " * all the tasks can be written with `numpy` commands, use `slicing` and `masks`, loops are not allowed!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19ee99b-b7e4-4599-94be-2eb482f5398b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here please"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d01e8d-40fe-4d10-9fab-2c1320ec4c54",
   "metadata": {},
   "source": [
    "### Epilogue\n",
    "\n",
    "If you try to use this approach for a temperature prediction for the whole day, it will obviously fail, since the program doesn't take into account the time of the test temperature nor the time of the found temperatures. So prediction for night temperatures are failing in any case. You can try to expand the solution to a daily temperature dataset. `meteostat` provides data with the function `Daily`, which then works similar as `Hourly`. The keyword for the temperature is `tmin` or `tmax` instead `temp`. So you can have a prediction for the min and max daily temperature. However, the search inside the database is much more difficult. One aspect is that the accuracy of the stored data is too high for a good search, I would convert all temperatures into integers and have a limit of 2° during the search to have enough data points for evaluation. Have a try!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3582d438-6bae-4a07-8088-972733c2b838",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
